---
layout: post
title: Google Congestion Control Algorithm
---

在实时音视频通信中，由于报文流量巨大，不可避免地遇到网络拥塞问题，因此如何解决拥塞变成了一大难题。这里将要介绍地是google的拥塞控制算法GCC（google congestion control），下面将结合标准文档以及实际使用讲解下自己对这个算法的理解。

# 1. 核心思想
在网络拥塞出现的时候，通常采用降低信源端发送码率来避免，因此该算法解决问题的核心在于`如何合理地动态估算并调整信源端发送带宽，以避免网络拥塞出现`。那怎么感知网络拥塞并估算带宽？业界主要有两种方法，即`基于丢包率(loss based)`估算和`根据时延(delay based)`估算，而GCC采用了这两种方法来进行拥塞感知和带宽估计，对应基于丢包的控制器（loss based controller）和基于时延的控制器（delay based controller）。

# 2. 工作原理
这个算法先估计带宽，再按照指定带宽发送码流。实现带宽算法有两种方法：

* 基于丢包的控制器和基于时延的控制器都运行在发送端
* 基于时延的控制器运行在接收端，基于丢包的控制器运行在发送端

## 2.1 带宽估计方法1
因为带宽估计需要丢包和时延信息，那这些信息怎么来？我们知道丢包接收端收到报文后算出丢包率后可以通过RTCP反馈给发送端，因此丢包率发送端是知道的，那么时延呢？GCC提出了一种per-packet protocol：

在通话前通过SDP协商支持google REMB(Receiver Estimated Maximum Bitrate) Feedback：
```
a=rtcp-fb:100 goog-remb
```

RTP接收端记录下报文接收时间和传输层序号，并使用RTCP feedback报文反馈给发送端。通常反馈是视频接收一帧发送一次，如果需要控制，可以增大发送间隔至100ms。

发送端收到FB报文后，可以获取{序号,接收时间数据}，将其输入基于时延的控制器。同时利用序号也可以计算丢包。

这样，两个控制器都可以运行在发送端，接收端根据这两个控制器估算出带宽。

<img src="/public/post/img/gcc-sender-side.png" style="width: 500px;margin:auto auto;"/>

## 2.2 带宽估计方法2
方法2，基于时延都控制器运行在接收端，是因为时延在接收端即可运算。GCC中使用了`RTP扩展头`携带报文发送时间abs-send-time来实现，接收端将绝对发送时间以及接收时间输入基于时延的控制器，最终输入带宽。发送端再将带宽通过`RTCP REMB`消息反馈给对端（其实也可以用`RTCP TMMBR`消息反馈带宽，见RTP AVPF）。这个方法里，丢包通过RTCP RR报文里面的fraction lost反馈给发送端。最终接收端反馈的带宽和丢包被输入发送端的基于丢包的控制器，最后输出目标带宽。

如果接收端没有实现RTCP FB来通过REMB或TMMBR反馈时延，也不会处理RTP扩展头，那么可以只在发送端运行基于丢包的控制器，直接利用RTCP反馈的丢包和环路时延评估带宽。

## 2.3 发送引擎
在计算完带宽后，发送端需要按照一定节奏发送报文。通常会创建一个节奏器队列（pacer queue），节奏器每隔burst_time（推荐值为5ms）向网路中发送报文，一组报文限制大小可以通过以下公式计算：

$$
group\_size = burst\_time*bitrate
$$

# 3. 基于时延的控制
基于时延的控制器可以被分解为四个部分： `预滤波`、`到达时间滤波器`、`过载检测器`、`码率控制器`。

## 3.1 到达时间模型
这个章节描述了一个滤波器，可以根据接收包组的时间连续地调整估计参数。这里定义了一个`接收时间间隔`：$$ t_i - t_{i-1} $$，即两个包组到达时间之差，相应地$$ T_i - T_{i-1} $$表示两个发送包组时间之差，即`发送时间间隔`。两个时间差相减得到时延差： 

$$ 
d_i = (t_i - t_{i-1}) - (T_i - T{i-1}) 
$$

接收时间$$ t_i $$表示的是一组包中的最后一个包接收的时间。如果当前包组相对之前的包组满足$$ t_i - t_{i-1} \gt T_i - T{i-1} $$，那说明当前包组相对之前的一个包组存在延迟。
在这个模型中，任何乱序的包都需要被丢弃。

下面我们对此包组之间的时延差$$ d_i $$进行建模：

$$
d_i = w_i
$$

其中$$ w_i $$是随机过程W的采样，它是链路能力、当前交叉网络、发送码率的函数。我们将W建模为白高斯随机过程`white Gaussian process`。如果通道被过度使用，通道出现拥塞，报文抖动增加，明显$$w_i$$的平均值会增加；如果网络路径上被清空后，$$w_i$$会降低；否则$$w_i$$保持不变。

我们将平均值$$ m_i $$从$$ d_i $$中分离出来：

$$
d_i = m_i + v_i
$$

其中$$ v_i $$表示网络抖动和其他未被模型捕获到的时延影响。

## 3.2 预滤波
预滤波旨在处理由于通道中断引起的短暂延时。当网络通道中断时，报文被放进缓冲队列，等到网络中断结束后，所有的报文一瞬间被转发。因此这里的做法是`将突发包合并成一组`，通过这个预滤波估计是否存在短暂的延时。

预滤波将突发包合并成一个组，需要满足以下任一条件：

* 一系列包在`burst_time`（见发送引擎中对此的描述）时间内一起被发送，组成一个组。
* 一个包在`burst_time`内被收到，包间时延变化$$d_i \lt 0$$，那么就认为是属于当前一组包。

## 3.3 到达时间滤波器
$$d_i$$我们可以很很容易通过包组时间得到，但是我们更希望能估计平均值$$m_i$$，并用它来评估当前受限链路是否过载。这个参数可以通过任何自适应滤波器得到，这里使用的是`卡尔曼滤波器Kalman filter`。因此下面将介绍如何使用卡尔曼滤波器，动态地估计平均值$$m_i$$。

假设i到i+1有如下的状态转换：

$$
m_{i+1} = m_i + u_i
$$

这里$$u_i$$是符合高斯随机过程的状态噪声，其均值为0，方差为：

$$
q_i = E[u_i^2]
$$

$$q_i$$推荐使用$$10^{-3}$$。


因此$$d_i = m_i + v_i$$对应卡尔曼滤波器中的观测值，方差为$$E[v_i^2]$$；$$m_{i+1} = m_i + u_i$$对应卡尔曼滤波器中的估计值，方差为$$E[u_i^2]$$。

卡尔曼滤波器递归地更新$$m_i$$的估计$$\bar{m}_i$$:

$$
z_i = d_i - \bar{m}_{i-1} \\
\bar{m}_i = \bar{m}_{i-1} + z_ik_i \\
k_i = (e_{i-1} + q_i)/(E[v_i^2] + (e_{i-1} + q_i)) \\
e_i = (1 - k_i * (e_{i-1} + q_i))
$$

其中$$k_i$$是卡尔曼增益，$$v_i$$的方差$$E[v_i^2]$$通过指数平均滤波器来估计:

$$
\bar{E}[v_i^2] = max(\alpha*E[v_{i-1}^2] + (1 - \alpha)*z_i^2, 1) \\
\alpha = (1-chi)^{30/(1000*f_{max})}
$$

其中，

$$
f_{max} = max[1/(T_j - T_{j-1})], j = i-K+1,...,i
$$

它是前K个收到的包组的最大码率。

chi是滤波器参数，范围[0.1, 0.001]。

如果$$z_i \gt 3sqrt(\bar{E}[v_i^2]) $$，使用$$z_i = 3sqrt(\bar{E}[v_i^2])$$来更新$$z_i$$。因为此时发包超出了通道限制，$$v_i$$不一定是一个高斯白噪声了。

通过卡尔曼滤波，我们可以比较准确地估计单向时延，用于评估当前链路是否过载。

## 3.4 过载检测器
通过上面的到达时间滤波器我们可以估算出时延差的平均值$$m_i$$，如何通过它判断当前链路是否过载呢？

将它和阈值$$Th$$比较，如果超过阈值则认为链路过载。一般不会仅仅检测出一次就认为是过载，需要持续一段时间$$T_{overuse}$$。如果$$m_i < m_{i-1}$$，即使$$m_i$$超过阈值一段时间，那么也不能认为是过载。同样，如果$$m_i < -Th$$，则认为是低载。如果既没有过载也没有低载，则是普通状态。

静态的阈值$$Th$$并不是一个很好的选择，通常会因为同时存在的TCP流而导致饥饿（starvation）。

<img src="/public/post/img/gcc-starve.png" style="width: 300px;margin:auto auto;"/>

为什么会出现这种情况呢？因为过小的阈值导致算法对$$m_i$$的变化很敏感，导致算法频繁地检测到过载信号，因此`基于时延的控制器`会因为这个时延变化不断减小评估的带宽。而`TCP是基于丢包(loss based)的流`，此时和TCP流竞争会导致自己饥饿。因此动态地调整过载阈值以达到最佳效果很有必要，下面将介绍如何动态地调整这个阈值。

$$
Th_i = Th_{i-1} + (t_i - t_{i-1})*K_i*(|m_i|*-Th_{i-1})
$$

其中，$$K_i=K_d$$，如果$$ \|m_i\| < Th_{i-1} $$，否则$$K_i=K_u$$。从这个式子看出，当$$m_i$$超过范围$$[-Th_{i-1}, Th_{i-1}]$$时，阈值需要增加；相反$$m_i$$跌落至这个范围，则阈值减小。

因此，当TCP流进入同样的瓶颈时，$$m_i$$会超出范围，此时阈值会增加，可以避免频繁产生过载信号。

如果一直满足$$\|m_i\| - Th_i > 15$$，此时抖动较大，不建议更新阈值$$Th$$。而$$Th_i$$建议范围为$$[6, 600]$$，太小的值会导致算法比较敏感。建议$$K_u \gt K_d$$，这样阈值可以`快升慢降`。以下是算法建议值：

$$
Th_0 = 12.5ms \\
T_{overuse} = 10ms \\
K_u = 0.01 \\
K_d = 0.00018
$$

## 3.5 码率控制
码率控制分为两个部分，一个是基于时延控制带宽估计，另一个是根据丢包控制。这两个控制的的目的都是为了更准确地估计带宽，使其能够和传输通道带宽匹配，并检测出拥塞。

当检测出过载时，基于时延的控制器评估的带宽会减小。

码率控制子系统会按照常数周期去执行带宽估计，它有3个状态：increase、decrease、hold。increase表明系统没有检测到拥塞，可以增大带宽；decrease表示系统检测到拥塞，需要减小带宽；hold状态会一直等待，直到需要增大带宽进入increase状态。其状态转换如下，空白表示保持当前状态：

|信号\当前状态|hold|increase|decrease|
|---|---|---|---|
|过载|decrease|decrease|-|
|正常|increase|-|hold|
|低载|-|hold|hold|

状态转换图如下：

<img src="/public/post/img/gcc-state.png" style="width: 300px;margin:auto auto;"/>

子系统最开始处于increase状态，直至检测到过载或者低载。增加按照倍数还是增加常数值的方式取决于当前状态。如果当前带宽和目标带宽相差很大，则使用倍数增加方式；如果很接近目标带宽则使用常数增加。

接收的带宽根据Ts的时间窗计算：

$$
\bar{R}_i = 1/T * \sum{L_j}, j = 1,...,N_i
$$

其中$$N_i$$表示上次T时间内收到的包个数，$$L_j$$表示第j个包的净荷大小。

当处于倍数增加中，估计带宽$$\bar{A}_i$$每秒增加8%：

$$
eta = 1.08^{min(time\_since\_last\_update\_ms / 1000, 1.0)} \\
\bar{A}_i = eta * \bar{A}_{i-1}
$$

当处于常数增加中，估计值每个响应时间增加最多半个包大小，响应时间间隔response_time_ms用环路时延RTT+100ms来估计，作为过载的预测和检测响应时间：

$$
response\_time\_ms = 100 + rtt_ms \\
\alpha = 0.5 * min(time\_since\_last\_update\_ms / response\_time\_ms, 1.0) \\
\bar{A}_i = \bar{A}_{i-1} + max(1000, \alpha * expected\_packet\_size\_bits)
$$

低带宽下，expected_packet_size_bits具有更缓慢的倾斜。假设当前帧率30，每帧1200字节，可以估计：

$$
avg\_packet\_size\_bits = \bar{A}_{i-1} / (30*1200*8)
$$


这个系统以来对通道过载来估计可用带宽，我们必须保证估计的带宽和当前发送带宽不能差太大，因此有以下的限制：

$$
\bar{A}_i \lt 1.5*\bar{R}_i
$$


当检测到过载时，系统需要转换到descrease状态，基于时延的带宽估计会将当前的带宽减少factor：

$$
\bar{A}_i = \beta*\bar{R}_i
$$

$$\beta$$取值范围： $$[0.8, 0.95]$$，建议使用0.85.

当检测到低载时，网络中的队列被清空，此时估计的可用带$$\bar{A}_i$$是低于实际可用带宽，于是当前子系统进入hold状态。而接收端可用带宽估计会持续保持（hold），等待队列稳定，保证延迟尽量小。

# 4. 基于丢包的控制
基于丢包的控制器根据环路时延RTT、丢包率、基于时延的控制器输出的带宽估计$$\bar{A}$$评估可用带宽，记为$$\bar{As}$$。

基于时延的控制器估算出来的可用带宽仅仅在网络路径上的缓存队列比较大的时候才比较可靠，如果缓存队列比较小，那么可以根据丢包来察觉是否过载。

* 如果从之前的报告中检测到2～10%的丢包，那么发送端的可用带宽$$\bar{As}_i$$保持不变。
* 如果丢包率超过10%，则$$\bar{As}_i = \bar{As}_{i-1}(1-0.5p)$$，其中p是丢包率
* 如果丢包率低于2%，那么带宽需要增加，$$\bar{As}_i = 1.05\bar{As}_{i-1}$$

基于丢包的估计和基于时间的估计会进行比较，最终取最小者：

$$
A_{final} = min\{\bar{As}, \bar{A}\}
$$





